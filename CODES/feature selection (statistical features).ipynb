{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "from helper import get_penmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(param1,param2):\n",
    "    d = 0\n",
    "    for i in range(0,len(param1)):\n",
    "        d+=np.nan_to_num(((param1[i]-param2[i])**2)/(param1[i]+param2[i]))\n",
    "    return d\n",
    "\n",
    "def dist(param1,param2,n1,n2):\n",
    "    mean1 = np.mean(param1)\n",
    "    mean2 = np.mean(param2)\n",
    "    var1  = np.var(param1)\n",
    "    var2 = np.var(param2)\n",
    "     \n",
    "    d = np.abs(mean1-mean2)\n",
    "    d/=(var1/n1 + var2/n2)**0.5\n",
    "    \n",
    "    return d\n",
    "\n",
    "def distance_distribution(features):\n",
    "    same_pens = {}\n",
    "    diff_pens = {}\n",
    "    \n",
    "    for k in range(1,113) :\n",
    "        for i in ['1','2']: \n",
    "            for n in ['1','2']:\n",
    "                for j in ['1','2','3','4','5','6','7','8'] :\n",
    "                    for m in ['1','2','3','4','5','6','7','8'] :\n",
    "                        try:\n",
    "                            if(i==n and j==m):\n",
    "                                continue    \n",
    "                            elif i==n and 'c_'+str(k)+'_'+n+'_'+m+'::'+i+'_'+j not in same_pens:\n",
    "                                same_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m] = compute_dist(features['c'+str(k)+'_'+i+'_'+j],features['c'+str(k)+'_'+n+'_'+m])\n",
    "                                #print(' same {}   :{}'.format('c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m,same_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m]))\n",
    "                    \n",
    "                            elif i!=n and 'c_'+str(k)+'_'+n+'_'+m+'::'+i+'_'+j not in diff_pens :                               \n",
    "                                diff_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m] = compute_dist(features['c'+str(k)+'_'+i+'_'+j],features['c'+str(k)+'_'+n+'_'+m])\n",
    "                                #print(' diff {}   :{}'.format('c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m,diff_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m]))\n",
    "                        except:\n",
    "                            \n",
    "                            pass\n",
    "     \n",
    "    \n",
    "    same_pens = [ v for v in same_pens.values() ]\n",
    "    diff_pens = [ v for v in diff_pens.values() ]\n",
    "   # print('Lengths same pens-{} different pens-{}'.format(len(same_pens),len(diff_pens)))\n",
    "    return same_pens,diff_pens\n",
    "\n",
    "def pen_distribution(features,a,pen_out):\n",
    "    same_pens = {}\n",
    "    diff_pens = {}\n",
    "    \n",
    "    for k in range(1,113) :\n",
    "        if(k in a[pen_out]):\n",
    "            for i in ['1','2']: \n",
    "                for n in ['1','2']:\n",
    "                    for j in ['1','2','3','4','5','6','7','8'] :\n",
    "                        for m in ['1','2','3','4','5','6','7','8'] :\n",
    "                            try:\n",
    "                                if(i==n and j==m):\n",
    "                                    continue    \n",
    "                                elif i==n and 'c_'+str(k)+'_'+n+'_'+m+'::'+i+'_'+j not in same_pens:\n",
    "                                    same_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m] =compute_dist(features['c'+str(k)+'_'+i+'_'+j],features['c'+str(k)+'_'+n+'_'+m])\n",
    "                                    #print(' same {}   :{}'.format('c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m,same_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m]))\n",
    "\n",
    "                                elif i!=n and 'c_'+str(k)+'_'+n+'_'+m+'::'+i+'_'+j not in diff_pens :                               \n",
    "                                    diff_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m] =compute_dist(features['c'+str(k)+'_'+i+'_'+j],features['c'+str(k)+'_'+n+'_'+m])\n",
    "                                    #print(' diff {}   :{}'.format('c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m,diff_pens['c_'+str(k)+'_'+i+'_'+j+'::'+n+'_'+m]))\n",
    "                            except:\n",
    "\n",
    "                                pass\n",
    "\n",
    "    \n",
    "    same_pens = [ v for v in same_pens.values() ]\n",
    "    diff_pens = [ v for v in diff_pens.values() ]\n",
    "   # print('Lengths same pens-{} different pens-{}'.format(len(same_pens),len(diff_pens)))\n",
    "    return same_pens,diff_pens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_btw_distributions(feature,a):\n",
    "    d = []\n",
    "    same_pens,diff_pens = distance_distribution(feature)\n",
    "    D = dist(same_pens,diff_pens,1465,1456)\n",
    "    for j in range(1,15):\n",
    "        same_pens_i,diff_pens_i= pen_distribution(feature,a,j)\n",
    "        d1 = len(same_pens_i)/2930*dist(same_pens_i,same_pens,len(same_pens_i),1465)\n",
    "        d2 = len(diff_pens_i)/2912*dist(diff_pens_i,diff_pens,len(diff_pens_i),1456)\n",
    "        d.append(d1+d2)\n",
    "        \n",
    "    return D-sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parameters(path,n_param):\n",
    "    hist_Y = {}\n",
    "    hist_Cb = {}\n",
    "    hist_Cr = {}\n",
    "    a = pd.read_csv(path)\n",
    "    for k in range(1,113):\n",
    "        for i in ['1','2']:\n",
    "            for j in ['1','2','3','4','5','6','7','8']:\n",
    "                try:\n",
    "                    \n",
    "                    hist_Y['c'+str(k)+'_'+i+'_'+j] = a['c'+str(k)+'_'+i+'_'+j][0:n_param] \n",
    "                    hist_Cb['c'+str(k)+'_'+i+'_'+j] = a['c'+str(k)+'_'+i+'_'+j][n_param:2*n_param]\n",
    "                    hist_Cr['c'+str(k)+'_'+i+'_'+j] = a['c'+str(k)+'_'+i+'_'+j][2*n_param:3*n_param]\n",
    "                    \n",
    "                    hist_Y['c'+str(k)+'_'+i+'_'+j].reset_index(inplace=True, drop=True)\n",
    "                    hist_Cb['c'+str(k)+'_'+i+'_'+j].reset_index(inplace=True, drop=True)\n",
    "                    hist_Cr['c'+str(k)+'_'+i+'_'+j].reset_index(inplace=True, drop=True)\n",
    "                    \n",
    "                except:\n",
    "                    break\n",
    "    return hist_Y,hist_Cb,hist_Cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(h1,f):\n",
    "    hist = {}    \n",
    "    for k in range(1,113):\n",
    "        for i in ['1','2']:\n",
    "            for j in ['1','2','3','4','5','6','7','8']:\n",
    "                try:\n",
    "                    hist['c'+str(k)+'_'+i+'_'+j] = np.array([h1['c'+str(k)+'_'+i+'_'+j][f]])\n",
    "                except:\n",
    "                    break\n",
    "    return hist\n",
    "\n",
    "def concat2(h1,h2):\n",
    "    hist = {}    \n",
    "    for k in range(1,113):\n",
    "        for i in ['1','2']:\n",
    "            for j in ['1','2','3','4','5','6','7','8']:\n",
    "                try:\n",
    "                    hist['c'+str(k)+'_'+i+'_'+j] = np.concatenate([h1['c'+str(k)+'_'+i+'_'+j],h2['c'+str(k)+'_'+i+'_'+j]])\n",
    "                except:\n",
    "                    break\n",
    "    return hist\n",
    "\n",
    "def concat3(h1,h2,h3):\n",
    "    hist = {}    \n",
    "    for k in range(1,113):\n",
    "        for i in ['1','2']:\n",
    "            for j in ['1','2','3','4','5','6','7','8']:\n",
    "                try:\n",
    "                    hist['c'+str(k)+'_'+i+'_'+j] = np.concatenate([h1['c'+str(k)+'_'+i+'_'+j],h2['c'+str(k)+'_'+i+'_'+j],h3['c'+str(k)+'_'+i+'_'+j]])\n",
    "                except:\n",
    "                    break\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_penmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mohit/Desktop/featuresUpdated/statistical_features.csv'\n",
    "y,cb,cr = load_parameters(path,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = {}\n",
    "\n",
    "for i in range(1,6):\n",
    "    fe[i] = separate(y,i-1)\n",
    "    fe[i+5] = separate(cb,i-1)\n",
    "    fe[i+10] = separate(cr,i-1)\n",
    "    \n",
    "for i in range(1,16):\n",
    "    mi = np.min([ v for v in fe[i].values() ])\n",
    "    mx = np.max([ v for v in fe[i].values() ])\n",
    "    for key in fe[i].keys():\n",
    "        fe[i][key]-=mi\n",
    "        fe[i][key]/=(mx-mi)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17.330539221563843)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Distances = {}\n",
    "for i in range(1,16):\n",
    "    Distances[i] = distance_btw_distributions(fe[i],a)\n",
    "        \n",
    "sorted_by_value = sorted(Distances.items(), key=lambda kv: kv[1],reverse =True)\n",
    "sorted_by_value[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### after comparing all features, we found that fe[1] i.e 1_y is the best and will be the starting point of our forward selection technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feycb = {}\n",
    "feycr  ={}\n",
    "feycbcr = {}\n",
    "for i in range(1,6):\n",
    "    feycb[i] = concat2(fe[i],fe[i+5])\n",
    "    feycr[i] = concat2(fe[i],fe[i+10])\n",
    "    feycbcr[i] = concat3(fe[i],fe[i+5],fe[i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmax will contain the selected features. dmax will contain the increment by adding the ith feature. \n",
    "# Fmax will contain a dict with all selected features concatenated together.\n",
    "\n",
    "fmax = [1]\n",
    "dmax = [17.330539221563843]\n",
    "Fmax = fe[1]\n",
    "Fmaxycb = feycb[1]\n",
    "Fmaxycr = feycr[1]\n",
    "Fmaxycbcr = feycbcr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dmax = sum(dmax)\n",
    "f= range(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.9019224424766499 5.676541862680484 3.601562734293463\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    Distancesy = {}\n",
    "    \n",
    "    for i in set(f)-set(fmax):\n",
    "        Distancesy[i] = distance_btw_distributions(concat2(Fmax,fe[i]),a) - Dmax\n",
    "        \n",
    "    sorted_by_value = sorted(Distancesy.items(), key=lambda kv: kv[1],reverse =True)\n",
    "    index = sorted_by_value[0][0]\n",
    "    dd = sorted_by_value[0][1]\n",
    "    \n",
    "    Distancesycb = distance_btw_distributions(Fmaxycb,a)-Dmax\n",
    "        \n",
    "    Distancesycr = distance_btw_distributions(Fmaxycr,a)-Dmax\n",
    "    \n",
    "    print(index,dd,Distancesycb,Distancesycr)\n",
    "    \n",
    "    if(dd<Distancesycb or dd<Distancesycr or dd<0):\n",
    "        if(max(Distancesycb,Distancesycr)>0):\n",
    "            dmax.append(max(Distancesycb,Distancesycr))\n",
    "            Dmax = sum(dmax)\n",
    "        break            \n",
    "                \n",
    "    fmax.append(index)\n",
    "    dmax.append(dd)\n",
    "    Fmax = concat2(fe[index],Fmax)\n",
    "    Dmax = sum(dmax)\n",
    "    Fmaxycb = concat2(feycb[index],Fmaxycb)\n",
    "    Fmaxycr = concat2(feycr[index],Fmaxycr)\n",
    "    Fmaxycbcr = concat2(feycbcr[index],Fmaxycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [17.330539221563843, 5.676541862680484])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmax,dmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### after applying our strategy, we found the following selection pattern. \n",
    "### 1y -> 1 ycb\n",
    "### so now we will apply forward selection on cbcr channel with fstart = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1.77588221350684 3.039936704972046\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    Distancesycb = {}\n",
    "    \n",
    "    for i in set(f)-set(fmax):\n",
    "        Distancesycb[i] = distance_btw_distributions(concat2(Fmaxycb,feycb[i]),a)-Dmax\n",
    "        \n",
    "    sorted_by_value = sorted(Distancesycb.items(), key=lambda kv: kv[1],reverse =True)\n",
    "    dd = sorted_by_value[0][1]\n",
    "    index = sorted_by_value[0][0]\n",
    "    \n",
    "    Distancesycbcr = distance_btw_distributions(Fmaxycbcr,a)-Dmax\n",
    "        \n",
    "    print(index,dd,Distancesycbcr)\n",
    "    if(dd<Distancesycbcr or dd<0):\n",
    "        if(Distancesycbcr>0):\n",
    "            dmax.append(Distancesycbcr)\n",
    "            Dmax = sum(dmax)\n",
    "        break\n",
    "                \n",
    "    fmax.append(index)\n",
    "    dmax.append(dd)\n",
    "    Dmax = sum(dmax)\n",
    "    Fmaxycb = concat2(feycb[index],Fmaxycb)\n",
    "    Fmaxycbcr = concat2(feycbcr[index],Fmaxycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [17.330539221563843, 5.676541862680484, 3.039936704972046])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmax,dmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequence of selection\n",
    "\n",
    "###  1y  -> 1ycb -> 1ycbcr\n",
    "\n",
    "### so we have to apply forward selection on ycbcr channel with fstart =[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 -0.13674504005429\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    Distancesycbcr = {}\n",
    "    for i in set(f)-set(fmax):\n",
    "        Distancesycbcr[i] = distance_btw_distributions(concat2(Fmaxycbcr,feycbcr[i]),a)-Dmax\n",
    "        \n",
    "    sorted_by_value = sorted(Distancesycbcr.items(), key=lambda kv: kv[1],reverse =True)\n",
    "    dd = sorted_by_value[0][1]\n",
    "    index = sorted_by_value[0][0]\n",
    "    \n",
    "    print(index,dd)\n",
    "    if(dd<0):\n",
    "        break\n",
    "                \n",
    "    fmax.append(index)\n",
    "    dmax.append(dd)\n",
    "    Dmax = sum(dmax)\n",
    "    Fmaxycbcr = concat2(feycbcr[index],Fmaxycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [17.330539221563843, 5.676541862680484, 3.039936704972046])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmax,dmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, f[1] i.e mean is selected in all color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets save the original features(not normalised) !\n",
    "\n",
    "best = concat3(separate(y,0),separate(cb,0),separate(cr,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c100_1_1</th>\n",
       "      <th>c100_1_2</th>\n",
       "      <th>c100_1_3</th>\n",
       "      <th>c100_1_4</th>\n",
       "      <th>c100_2_1</th>\n",
       "      <th>c100_2_2</th>\n",
       "      <th>c100_2_3</th>\n",
       "      <th>c101_1_1</th>\n",
       "      <th>c101_1_2</th>\n",
       "      <th>c101_1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>c99_2_3</th>\n",
       "      <th>c9_1_1</th>\n",
       "      <th>c9_1_2</th>\n",
       "      <th>c9_1_3</th>\n",
       "      <th>c9_1_4</th>\n",
       "      <th>c9_1_5</th>\n",
       "      <th>c9_1_6</th>\n",
       "      <th>c9_1_7</th>\n",
       "      <th>c9_2_1</th>\n",
       "      <th>c9_2_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72.486643</td>\n",
       "      <td>75.916715</td>\n",
       "      <td>68.991495</td>\n",
       "      <td>73.673966</td>\n",
       "      <td>47.518584</td>\n",
       "      <td>45.440278</td>\n",
       "      <td>43.909430</td>\n",
       "      <td>43.503347</td>\n",
       "      <td>42.037456</td>\n",
       "      <td>41.841573</td>\n",
       "      <td>...</td>\n",
       "      <td>44.992625</td>\n",
       "      <td>91.557559</td>\n",
       "      <td>81.518617</td>\n",
       "      <td>80.132029</td>\n",
       "      <td>77.692927</td>\n",
       "      <td>76.910283</td>\n",
       "      <td>79.434095</td>\n",
       "      <td>79.408792</td>\n",
       "      <td>67.531250</td>\n",
       "      <td>70.691566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.569493</td>\n",
       "      <td>134.792074</td>\n",
       "      <td>134.547838</td>\n",
       "      <td>134.412409</td>\n",
       "      <td>128.239646</td>\n",
       "      <td>128.162350</td>\n",
       "      <td>128.126265</td>\n",
       "      <td>129.474020</td>\n",
       "      <td>129.556769</td>\n",
       "      <td>129.348315</td>\n",
       "      <td>...</td>\n",
       "      <td>128.227139</td>\n",
       "      <td>119.373093</td>\n",
       "      <td>118.459441</td>\n",
       "      <td>119.431133</td>\n",
       "      <td>119.322599</td>\n",
       "      <td>120.026528</td>\n",
       "      <td>119.495606</td>\n",
       "      <td>119.349602</td>\n",
       "      <td>115.936298</td>\n",
       "      <td>113.386747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.109175</td>\n",
       "      <td>125.982194</td>\n",
       "      <td>126.091425</td>\n",
       "      <td>125.944343</td>\n",
       "      <td>134.134867</td>\n",
       "      <td>133.838423</td>\n",
       "      <td>133.706979</td>\n",
       "      <td>127.372330</td>\n",
       "      <td>127.478736</td>\n",
       "      <td>127.793820</td>\n",
       "      <td>...</td>\n",
       "      <td>134.044985</td>\n",
       "      <td>172.149792</td>\n",
       "      <td>177.789894</td>\n",
       "      <td>174.333333</td>\n",
       "      <td>175.864290</td>\n",
       "      <td>172.880477</td>\n",
       "      <td>177.645577</td>\n",
       "      <td>176.975078</td>\n",
       "      <td>178.679087</td>\n",
       "      <td>186.748996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 854 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     c100_1_1    c100_1_2    c100_1_3    c100_1_4    c100_2_1    c100_2_2  \\\n",
       "0   72.486643   75.916715   68.991495   73.673966   47.518584   45.440278   \n",
       "1  134.569493  134.792074  134.547838  134.412409  128.239646  128.162350   \n",
       "2  126.109175  125.982194  126.091425  125.944343  134.134867  133.838423   \n",
       "\n",
       "     c100_2_3    c101_1_1    c101_1_2    c101_1_3     ...         c99_2_3  \\\n",
       "0   43.909430   43.503347   42.037456   41.841573     ...       44.992625   \n",
       "1  128.126265  129.474020  129.556769  129.348315     ...      128.227139   \n",
       "2  133.706979  127.372330  127.478736  127.793820     ...      134.044985   \n",
       "\n",
       "       c9_1_1      c9_1_2      c9_1_3      c9_1_4      c9_1_5      c9_1_6  \\\n",
       "0   91.557559   81.518617   80.132029   77.692927   76.910283   79.434095   \n",
       "1  119.373093  118.459441  119.431133  119.322599  120.026528  119.495606   \n",
       "2  172.149792  177.789894  174.333333  175.864290  172.880477  177.645577   \n",
       "\n",
       "       c9_1_7      c9_2_1      c9_2_2  \n",
       "0   79.408792   67.531250   70.691566  \n",
       "1  119.349602  115.936298  113.386747  \n",
       "2  176.975078  178.679087  186.748996  \n",
       "\n",
       "[3 rows x 854 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = pd.DataFrame(best)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.to_csv('/home/mohit/Desktop/featuresUpdated/statistical_Selectedfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
